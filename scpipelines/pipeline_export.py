##############################################################################
#
#   Kennedy Institute of Rheumatology
#
#   $Id$
#
#   Copyright (C) 2020 Stephen Sansom
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################

"""===========================
Pipeline Export
===========================

:Author: Kathrin Jansen
:Release: $Id$
:Date: |today|
:Tags: Python

Overview
========

This pipeline performs the following task:

* convert anndata to seurat object

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_emptydrops.py config


Input files
-----------

The pipeline is run from the anndata object created by pipeline_integration.py.
A sample name, the path to the anndata object (path) and (optional) path to
the folder with the original matrix data (matrixdir) are specified in
input_samples.tsv. If matrixdir is specified then market matrix format input
for the full dataset are expected. The alternative option is to supply the
path to a anndata object instead of the matrixdir. The option use_full_anndata
in pipeline.yml needs to be set if anndata should be used.

The column names in input_samples.tsv need to be sample_id, path and
either matrixdir or anndata.
The dim reduction to include in the output seurat object is specified in
the pipeline.yml.


Dependencies
------------

This pipeline requires:
* cgat-core: https://github.com/cgat-developers/cgat-core
* python - scanpy, anndata
* R - Seurat

Pipeline output
===============

The pipeline returns:
A seurat object.

Code
====

"""
from ruffus import *
from pathlib import Path
import sys
import os
import yaml
import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools
import pandas as pd

# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])

# set the location of the tenx code directory
if "code_dir" not in PARAMS.keys():
    PARAMS["code_dir"] = Path(__file__).parents[1]
else:
    raise ValueError("Could not set the location of the code directory")


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ######## Check input samples file and that the input exists ############### #
# ########################################################################### #


@originate("input.check.sentinel")
def checkInputs(outfile):
    '''Check that input_samples.tsv exists and the path given in the file
       is a valid directorys. '''

    if not os.path.exists("input_samples.tsv"):
        raise ValueError('File specifying the input samples is not present.'
                         'The file needs to be named "input_samples.tsv" ')

    samples = pd.read_csv("input_samples.tsv", sep='\t')
    for p in samples["path"]:
        if not os.path.exists(p):
            raise ValueError('Input file does not exist.')
    IOTools.touch_file(outfile)


def genClusterJobs():
    ''' Generate cluster jobs for each sample '''
    samples = pd.read_csv("input_samples.tsv", sep='\t')
    infile = None
    samples.set_index("sample_id", inplace=True)

    for sample_name in samples.index:
        sample_dir = sample_name + ".exp.dir"
        out_sentinel = os.path.join(sample_dir, "export_anndata.sentinel")
        yield(infile, out_sentinel)


# ########################################################################### #
# ########################## Run EmptyDrops ################################# #
# ########################################################################### #

@follows(checkInputs)
@files(genClusterJobs)
def exportFromAnndata(infile, outfile):
    ''' Run python script to extract data from anndata object '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    options = {}

    sample_name = outfile.split("/")[0][:-len(".exp.dir")]
    samples = pd.read_csv("input_samples.tsv", sep='\t')
    samples.set_index("sample_id", inplace=True)
    infile_h5 = samples.loc[sample_name, "path"]
    options["infile_h5"] = infile_h5
    options["outdir"] = outdir
    options["dim_name"] = PARAMS["dim_name"]
    if PARAMS["use_full_anndata"]:
        options["infile_full"] = samples.loc[sample_name, "anndata"]
    if PARAMS["seurat_data_only"]:
        options["seurat_data_only"] = PARAMS["seurat_data_only"]

    # add metadata options                                                                   
    if os.path.isfile(PARAMS["metadata_path"]):
        options["metadata_file"] = PARAMS["metadata_path"]
        options["metadata_id"] = PARAMS["metadata_id_col"]

    log_file = outfile.replace("sentinel","log")
    job_threads = PARAMS["python_threads"]
    if ("G" in PARAMS["python_memory"] or
    "M" in PARAMS["python_memory"] ):
        job_memory = PARAMS["python_memory"]

    task_yaml_file = os.path.abspath(os.path.join(outdir, "anndata_tsv.yml"))
    with open(task_yaml_file, 'w') as yaml_file:
        yaml.dump(options, yaml_file)

    statement = '''python %(code_dir)s/python/writeAnndata_to_tsv.py
                   --task-yml=%(task_yaml_file)s &> %(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(exportFromAnndata,
           regex(r"(.*).exp.dir/export_anndata.sentinel"),
           r"\1.exp.dir/create_seurat_object.sentinel")
def createSeuratObject(infile, outfile):
    ''' Run R script to create seurat object '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    options = {}
    sample_name = outfile.split("/")[0][:-len(".exp.dir")]
    samples = pd.read_csv("input_samples.tsv", sep='\t')
    samples.set_index("sample_id", inplace=True)
    # set matrixdir if required
    if not PARAMS["use_full_anndata"]:
        matrixdir = samples.loc[sample_name, "matrixdir"]
        options["matrixdir"] = matrixdir
    if PARAMS["write_rds"]:
        options["output_format"] = "rds"
    else:
        options["output_format"] = "h5seurat"

    if PARAMS["seurat_data_only"]:
        options["seurat_data_only"] = True

    # this is used to get dim reduction directly from tsv file
    infile_h5 = samples.loc[sample_name, "path"]
    options["infile_h5"] = infile_h5
    options["outdir"] = outdir
    options["dim_name"] = PARAMS["dim_name"]
    if PARAMS["subsets_run"]:
        if ',' in str(PARAMS["subsets_cell_numbers"]):
            cell_numbers = [str(x) for x in PARAMS["subsets_cell_numbers"].split(",")]
        else:
            cell_numbers = [PARAMS["subsets_cell_numbers"]]
        options["cell_numbers"] = cell_numbers

    log_file = outfile.replace("sentinel","log")
    job_threads = PARAMS["R_threads"]
    if ("G" in PARAMS["R_memory"] or
    "M" in PARAMS["R_memory"] ):
        job_memory = PARAMS["R_memory"]

    task_yaml_file = os.path.abspath(os.path.join(outdir, "create_seurat.yml"))
    with open(task_yaml_file, 'w') as yaml_file:
        yaml.dump(options, yaml_file)

    statement = '''Rscript %(code_dir)s/R/create_seurat_object.R
                   --task_yml=%(task_yaml_file)s
                   --log_filename=%(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)


# ---------------------------------------------------
# Generic pipeline tasks

@follows(createSeuratObject)
def full():
    '''
    Run the full pipeline.
    '''
    pass


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
