'''
======================
pipeline_tcr_join.py
======================


Overview
========

The pipeline joins the dandelion TCR outputs from multiple projects (if specified) 
into a single dandelion object. In future it is intended to also join a Dandelion object
with its matching GEX anndata object and perform additional analysis such as TCRmatch and
GLIPH analysis, however this has not been implemented.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` for general
information on how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured:file:`pipeline_tcr_join.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_tcr_join.py config


Inputs
------

In addition to the "pipeline_tcr.yml" file, the pipeline requires inputs: 

# Inputs generated from running pipeline_tcr.py

Dependencies
------------

This pipeline requires:
* cgat-core: https://github.com/cgat-developers/cgat-core
* cellranger: https://support.10xgenomics.com/single-cell-gene-expression/
* apptainer: https://github.com/apptainer/apptainer

Pipeline logic
--------------

The pipeline is designed to integrate Dandelion pre-processed TCR data from multiple projects.


Pipeline output
---------------

The pipeline returns:

* a dandelion object consisting of joined dandelion objects from different projects

* (future output) an anndata object with the tcr information added

* (future output) a series of plots and tables summarising the data


Code
====

'''

from ruffus import *
from pathlib import Path
import sys
import os
import glob
import re
import sqlite3
import yaml
import csv
import shutil
# All dandelion work is done through apptainer now
#import dandelion as ddl
import scanpy as sc
# import psutil
# from contextlib import contextmanager

import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import pandas as pd
import numpy as np

# import local pipeline utility functions
import cellhub.tasks as T
import cellhub.tasks.cellranger as cellranger
import cellhub.tasks.samples as samples
import logging


# ########################################################################### #
# ###################### Set up the logging ################################# #
# ########################################################################### #

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
L = logging.getLogger("pipeline_tcr_join.py")

# Attempt to retrieve SLURM_JOB_ID
slurm_job_id = os.getenv('SLURM_JOB_ID', 'Not set')
L.info(f'pipeline_tcr_join.py SLURM_JOB_ID: {slurm_job_id}')


# -------------------------- Pipeline Configuration -------------------------- #


# Override function to collect config files
P.control.write_config_files = T.write_config_files

# load options from the yml file
P.parameters.HAVE_INITIALIZED = False
PARAMS = P.get_parameters(T.get_parameter_file(__file__))

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]


if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


dirprefix_string = PARAMS.get("dirprefix", "")  
projects_string = PARAMS.get("projects", "")
projects_list = projects_string.split(';')

# Running GLIPH is not yet implemented
rungliph_bool = PARAMS.get("gliph_run", False)

# Using TCRmatch and joining to a GEX object is experimental
runTCRmatch_bool = PARAMS.get("TCRmatch_run", False) 
runGEXjoin_bool = PARAMS.get("join_join_gex", False)

# Only running on unfiltered has been implemented, leave as False
filteredJoin_bool = PARAMS.get("join_filtered", False) 



# Joining the unfiltered outputs
def dandelion_input_files(projects_list,dirprefix_string):
   globs = [] 
   for project in projects_list:
      globs += glob.glob(f"{dirprefix_string}{project}/cellhub/dandelion.dir/dandelion_unfiltered_*.h5ddl")

   return globs


@merge(dandelion_input_files(projects_list,dirprefix_string),
         r"gex_tcr_join.dir/dandelion_merged.sentinel")
def dandelion_join(input_files, outfile):
   '''
   Merge all dandelion files and create a single dandelion object
   '''




   # Directory where the output file will be saved
   output_dir = os.path.dirname(outfile)

   # Ensure the output directory exists
   if not os.path.exists(output_dir):
      os.makedirs(output_dir, exist_ok=True)  


   # Convert globs to a string where each list item is seperated by a comma
   input_files_string = ",".join(input_files)
   L.info("The input_files_string is: %s", input_files_string)

   t = T.setup(input_files_string, outfile, PARAMS,
               memory=PARAMS["resources_memory"],
               cpu=PARAMS["resources_cores"])

   statement = '''
               apptainer run 
               --writable-tmpfs
               -B $PWD
               -B %(cellhub_code_dir)s/python/
               -B %(dirprefix)s
               -H $PWD/dandelion.dir
               $DNDLN
               python %(cellhub_code_dir)s/python/dandelion_join.py
                  --dandelion_input_files %(input_files_string)s
                  --output_file %(outfile)s
                  &> %(log_file)s
                  ''' % dict(PARAMS, 
                           **t.var, 
                           **locals())


   L.info("The dandelion_join statement is: %s", statement)


   P.run(statement, **t.resources)

   IOTools.touch_file(outfile)

# This is so that TCR match doesn't get upset whenever there is a stop codon in the CDR3 sequence
def filter_file(input_file_name, output_file_name, exclude_value, field_number):
    """
    Filters lines from the input file and writes them to the output file,
    excluding lines where the specified field equals the exclude_value.
    
    Parameters:
    input_file_name (str): The path to the input file.
    output_file_name (str): The path to the output file.
    exclude_value (str): The value to exclude from the specified field.
    field_number (int): The number of the field to check, 1-based indexing.
    """
    with open(input_file_name, 'r') as infile, open(output_file_name, 'w') as output_file:
        for line in infile:
            fields = line.strip().split('\t')
            # Adjust for zero-based indexing
            index = field_number - 1
            if len(fields) > index and fields[index] != exclude_value:
                output_file.write(line)


@active_if(runTCRmatch_bool) 
@follows(dandelion_join)
@transform(dandelion_join,
            suffix("merged_unfiltered.sentinel"),
            "merged_unfiltered_TCRmatch.sentinel")
def TCRmatch(infile, outfile):
   '''
   Create TCR match output from the Dandelion AIRR output
   '''

   available_cpus = PARAMS["resources_cores"]


   AIRR_file = outfile.replace("merged_unfiltered_TCRmatch.sentinel", "merged_unfiltered_AIRR.tsv")
   productive_file =  AIRR_file.replace(".tsv", "_productive.tsv")


   #Filter unproductive
   filter_file(AIRR_file, productive_file, "F", 4)


   tcr_database_string = PARAMS.get("TCRmatch_databases", "")
   tcr_database_list = tcr_database_string.split(';')


   for tcr_database in tcr_database_list:

         
      tcr_database_simple = os.path.basename(tcr_database.replace(".tsv", ""))
      # Define the tcr match output file based on the sample name and database used
      TCRmatch_outfile = f"gex_tcr_join.dir/dandelion_merged.TCRmatch.{tcr_database_simple}.tsv"


      t = T.setup(infile, outfile, PARAMS,
                  memory=PARAMS["resources_memory"],
                  cpu=PARAMS["resources_cores"])

      statement = '''
         tcrmatch  
         -i %(productive_file)s
         -t %(available_cpus)s
         -s .97
         -d  %(tcr_database)s
         -a > %(TCRmatch_outfile)s
         ''' % dict(PARAMS, 
                     **t.var, 
                     **locals())

      L.info("The TCRmatch statement is: %s", statement)

      P.run(statement, **t.resources)
      
   IOTools.touch_file(outfile)




@active_if(runGEXjoin_bool) 
@follows(dandelion_join)
@transform(dandelion_join,
            suffix("merged.sentinel"),
            "gex_merged.sentinel")
def dandelion_gex_join(infile, outfile):
   '''
   Merge the dandelion object with the gene expression object
   '''
 

   # Always working with merged unfiltered datasets, performing filtering last
   vdj_file_path = outfile.replace("gex_merged.sentinel", "merged_unfiltered.h5ddl")

   
   output_dir = os.path.dirname(outfile)
   
   # Not picked up with locals unless included here
   gex_file_string = PARAMS.get("gex_file", "")

   gex_dir = os.path.dirname(gex_file_string)
   
   join_cores_local = PARAMS.get("join_cores", 1)

   if join_cores_local > 1:
      join_cores_local = join_cores_local - 1

   if filteredJoin_bool:
      outfile_prefix_string = outfile.replace(".sentinel", "_filtered")
   else:
      outfile_prefix_string = outfile.replace(".sentinel", "_unfiltered")

   # Setup the task with total cores, but then use cores - 1 for the apptainer (it gets this from locals)
   t = T.setup(infile, outfile, PARAMS,
               memory=PARAMS["join_memory"],
               cpu=PARAMS["join_cores"])



   # Attempt to get and print the 'PWD' environment variable
   current_directory = os.environ.get('PWD')
   L.info("The value of PWD before submission is: %s", current_directory)


   statement = '''
               apptainer run 
               --writable-tmpfs
               -B $PWD
               -B %(gex_file_string)s
               -B %(cellhub_code_dir)s/python/
               -H $PWD/dandelion.dir
               $DNDLN
               python %(cellhub_code_dir)s/python/tcr_join.py
                  --dandelion_path %(vdj_file_path)s
                  --gex_path %(gex_file_string)s
                  --cores_to_use %(join_cores_local)s
                  --outfile_prefix %(outfile_prefix_string)s
                  &> %(log_file)s
                  ''' % dict(PARAMS, 
                           **t.var, 
                           **locals())

   L.info("The dandelion_gex_join statement is: %s", statement)

   P.run(statement, **t.resources)

   IOTools.touch_file(outfile)
   
@follows(dandelion_gex_join)
#@follows(TCRmatch)
def full():
    '''
    Run the full pipeline.
    '''
    pass



def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))