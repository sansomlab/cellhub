"""
===================
pipeline_cluster.py
===================

Overview
========

This pipeline performs clustering of integrated single cell datasets. Starting from an anndata
object with integrated coordinates (e.g. from Harmony or scVI) the pipeline:

* Computes the neighbour graph using the HNSW alogrithm
* Performs UMAP compuation and Leiden clustering (with ScanPy)
* Visualises QC statistics on the UMAPs and by cluster
* Visualises singleR results
* Finds cluster marker genes (using the ScanPy 'rank_genes_groups' function)
* Performs pathway analysis of the cluster phenotypes (with gsfisher)
* Prepares marker gene and summary reports
* Export an anndata for viewing with cellxgene

For plotting of data in R, the pipeline saves the input anndata in loom format and
reads data in R with the loomR library.


Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to perform the clustering in a new directory.

The pipeline requires a configured :file:`pipeline_cluster.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cluster.py config

Inputs
------

The pipeline starts from an anndata object with the following structure.

* anndata.var.index -> gene names - these will be displayed in the plots
* anndata.var.gene_ids -> ensembl gene ids, optional but required for pathway analysis
* anndata.X -> scaled data (a dense matrix)
* anndata.layers["counts"] -> raw counts (a sparse matrix)
* anndata.layers["log1p"] -> total count normalised, 1og1p transformed data (a sparse matrix)
* anndata.obs -> metadata (typically passed through from original cellhub object)
* anndata.obsm["X_rdim_name"] -> containing the integrated coordinates (where "rdim_name" matches 
  the "runspec_rdim_name" parameter). TODO: rename this parameter.



It is strongly recommended to retain the information for all of the genes in all of the matrices 
(i.e. do not subset to HVGs!). This is important for marker gene discovery and pathway analysis.


Pipeline output
===============

The pipeline produces the following outputs:

1. Summary report

- Containing the overview UMAP plots, visualisation of QC and SingleR information 
- The result of the per-cluster pathway analysis

2. Marker report

- Containing heatmaps, violin plots, expression dotplots, MA and volcano plots for 
  each cluster.

3. xlsx spreadsheets for the marker gene and pathway results

4. Anndata objects ready to be viewed with cellxgene


Code
====

"""

#region Imports and Configuration

import os
import sys
import gzip
import glob
import shutil

from pathlib import Path
import pandas as pd

import yaml
import textwrap
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks as T
import cellhub.tasks.cluster as C
from cellhub.tasks.report import template as template

# -------------------------- Pipeline Configuration -------------------------- #

# Override function to collect config files
P.control.write_config_files = T.write_config_files

# load options from the yml file
P.parameters.HAVE_INITIALIZED = False
PARAMS = P.get_parameters(T.get_parameter_file(__file__))

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]

# automatically set paths on the cellhub api
cellhub_ensembl_annotations = os.path.join(PARAMS["source_cellhub"],
            "api/annotation/ensembl/ensembl.to.entrez.tsv.gz")

if __name__ == "__main__" and not os.path.exists(cellhub_ensembl_annotations):
    raise ValueError("cellhub ensembl annotations file not found: " +
                     cellhub_ensembl_annotations)
    
PARAMS["cellhub_ensembl_annotations"] = cellhub_ensembl_annotations

cellhub_kegg_pathways = os.path.join(PARAMS["source_cellhub"],
                                  "api/annotation/kegg/kegg.pathways.rds")

if __name__ == "__main__" and not os.path.exists(cellhub_kegg_pathways):
    raise ValueError("cellhub kegg pathways file not found")
PARAMS["cellhub_kegg_pathways"] = cellhub_kegg_pathways

# ------------------------------ Pipeline Tasks ------------------------------ #

#endregion

#region Setup

@files(None, "task.summary.table.tex")
def taskSummary(infile, outfile):
    '''Make a summary of optional tasks that will be run'''

    tasks, run = [], []

    for k,v in PARAMS.items():
        if k.startswith("run_"):
            tasks.append(k[4:])
            run.append(str(v))

    tab = pd.DataFrame(list(zip(tasks,run)),columns=["task","run"])
    tab.to_latex(buf=outfile, index=False, escape=True)

    
@files(PARAMS["source_anndata"],
       "preflight.sentinel")
def preflight(infile, outfile):
    '''
       Preflight sanity checks.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"],
                make_outdir=False)

    if PARAMS["markers_conserved"]:
        conserved = "--conserved"
    else:
        conserved = ""
        
    if PARAMS["run_genesets"]:
        geneids = "--gene_ids"
    else:
        geneids = ""
        
    max_rdims = max(int(x.strip()) for x in 
                    str(PARAMS["runspecs_n_components"]).strip().split(","))

    statement = '''python %(cellhub_code_dir)s/python/cluster_preflight.py
                   --anndata=%(infile)s
                   --reduced_dims_name=%(source_rdim_name)s
                   --max_reduced_dims=%(max_rdims)s
                   %(conserved)s
                   %(geneids)s
                   --conserved_factor=%(markers_conserved_factor)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


@follows(preflight)
@files(PARAMS["source_anndata"],
       "metadata.dir/metadata.sentinel")
def metadata(infile, outfile):
    '''
       Export the metadata (obs) from the source anndata
       for use in the plotting tasks
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    if PARAMS["markers_conserved"]:
        conserved = "--conserved"
    else:
        conserved = ""

    outfile_name = outfile.replace(".sentinel", ".tsv.gz")

    statement = '''python %(cellhub_code_dir)s/python/cluster_metadata.py
                   --source_anndata=%(infile)s
                   %(conserved)s
                   --conserved_factor=%(markers_conserved_factor)s
                   --outfile=%(outfile_name)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

@follows(preflight)
@files(PARAMS["source_anndata"],
       "loom.dir/loom.sentinel")
def loom(infile, outfile):
    '''
       Export the data to the loom file format. This is used
       as an exchange format for plotting in R. 
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    loom_dir= os.path.dirname(outfile)
    
    layers = set([PARAMS["source_heatmap_matrix"], "log1p"])
    
    statements = []

    for layer in layers:
    
        layer_log_file = os.path.join(loom_dir, layer + ".log")
    
        stat = '''python %(cellhub_code_dir)s/python/cluster_loom.py
                  --anndata=%(infile)s
                  --layer=%(layer)s
                  --loomdir=%(loom_dir)s
                  &> %(layer_log_file)s
                ''' % dict(PARAMS, **t.var, **locals())
                
        statements.append(stat)

    P.run(statements, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Neighbor graph

# ########################################################################### #
# ###################### Compute the neighbor graph ######################### #
# ########################################################################### #


def genNeighbourGraphs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    outname = "neighbour.graph.sentinel"

    infile = PARAMS["source_anndata"]

    for comps in components:

        outdir = "out." + comps + ".comp.dir"

        outfile = os.path.join(outdir, outname)
        yield [infile, outfile]

@follows(preflight)
@files(genNeighbourGraphs)
def neighbourGraph(infile, outfile):
    '''
       Compute the neighbor graph.
       A miniminal anndata is saved for UMAP computation and clustering.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    reductiontype = PARAMS["dimreduction_method"]
    ncomps = t.components

    # set the job threads and memory
    if PARAMS["neighbors_full_speed"]:
        full_speed = "--fullspeed"
    else:
        full_speed = ""

    outfile_name = outfile.replace(".sentinel", ".h5ad")

    statement = '''python %(cellhub_code_dir)s/python/cluster_neighbor_graph.py
                   --source_anndata=%(infile)s
                   --reduced_dims_name=%(source_rdim_name)s
                   --outfile=%(outfile_name)s
                   --ncomps=%(ncomps)s
                   --method=%(neighbors_method)s
                   --threads=%(neighbors_threads)s
                   --k=%(neighbors_n_neighbors)s
                   --metric=%(neighbors_metric)s
                   %(full_speed)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Cluster

# ########################################################################### #
# ############################ Clustering ################################### #
# ########################################################################### #

def genScanpyClusterJobs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    if PARAMS["runspecs_cluster_resolutions"]:
        resolutions = [ x.strip() for x in
                        str(PARAMS["runspecs_cluster_resolutions"]).split(",") ]

    outname = "scanpy.clusters.sentinel"

    for comps in components:

        outdir = "out." + comps + ".comp.dir"
        infile = os.path.join(outdir,
        "neighbour.graph.h5ad")

        if PARAMS["runspecs_predefined_clusters"] :

            subdir = "cluster.predefined.dir"
            outfile = os.path.join(outdir, subdir, outname)
            yield [infile, outfile]

        if PARAMS["runspecs_cluster_resolutions"]:
            for resolution in resolutions:

                subdir = "cluster." + resolution + ".dir"
                outfile = os.path.join(outdir, subdir, outname)
                yield [infile, outfile]


@follows(neighbourGraph)
@files(genScanpyClusterJobs)
def scanpyCluster(infile, outfile):
    '''
       Discover clusters using ScanPy.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    if not "cluster.predefined.dir" in t.outdir:

        statement = '''python %(cellhub_code_dir)s/python/cluster_cluster.py
                   --anndata=%(infile)s
                   --algorithm=%(cluster_algorithm)s
                   --resolution=%(resolution)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

        P.run(statement, **t.resources)

    IOTools.touch_file(outfile)


@transform(scanpyCluster,
           regex(r"(.*)/scanpy.clusters.sentinel"),
           r"\1/cluster.sentinel")
def cluster(infile, outfile):
    '''
    Post-process the clustering result.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    scanpy_cluster_tsv = infile.replace(".sentinel",".tsv.gz")

    if "cluster.predefined.dir"  in t.indir:
        predefined='--predefined=' + PARAMS["runspecs_predefined_clusters"]
    else:
        predefined=""

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_post_process.R
                   --clusters=%(scanpy_cluster_tsv)s
                   %(predefined)s
                   --mincells=10
                   --outdir=%(outdir)s
                   > %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_compare_clusters"])
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/compare.clusters.sentinel")
def compareClusters(infile, outfile):
    '''
       Draw a dendrogram showing the relationship between the clusters.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    reductiontype = PARAMS["source_rdim_name"]

    statement = '''python %(cellhub_code_dir)s/python/cluster_compare.py
                   --source_anndata=%(source_anndata)s
                   --clusterids=%(cluster_ids)s
                   --ncomp=%(components)s
                   --outdir=%(outdir)s
                   --reduced_dims_name=%(reductiontype)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### compare the clusters across resolutions ################### #
# ########################################################################### #

nresolutions = len(str(PARAMS["runspecs_cluster_resolutions"]).split(","))

@active_if(nresolutions > 1)

@follows(cluster)
@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/clustree.sentinel")
def clustree(infile, outfile):
    '''
       Run clustree.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    id_files = [ os.path.join(t.outdir,
                              "cluster." + r + ".dir",
                              "cluster_ids.tsv.gz")
                 for r in t.resolutions ]

    res_str = ",".join(t.resolutions)
    id_files_str = ",".join(id_files)

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_clustree.R
                   --resolutions=%(res_str)s
                   --clusteridfiles=%(id_files_str)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

@active_if(PARAMS["run_paga"])
@follows(neighbourGraph)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/paga.dir/paga.sentinel")
def paga(infile, outfile):
    '''
       Run partition-based graph abstraction (PAGA)
       see: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1663-x
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_high"])

    statement = '''python %(cellhub_code_dir)s/python/cluster_paga.py
                   --anndata=%(neighbour_graph_anndata)s
                   --outdir=%(outdir)s
                   --cluster_ids=%(cluster_ids)s
                   --cluster_colors=%(cluster_colors)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

# endregion

#region UMAP

# ########################################################################### #
# ############### UMAP analysis and related plots ########################### #
# ########################################################################### #

@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/umap.dir/umap.sentinel")
def UMAP(infile, outfile):
    '''
       Compute the UMAP layout.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"],
                cpu=2)

    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''python %(cellhub_code_dir)s/python/cluster_umap.py
                             --anndata=%(neighbour_graph_anndata)s
                             --mindist=%(mindist)s
                             --outdir=%(outdir)s
                             &> %(mindist_log_file)s
                     ''' % dict(PARAMS, **t.var, **locals())

        statements.append(statement)

    P.run(statements, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region UMAP plots

# ########################################################################### #
# ###### Visualise gene expression across cells in reduced dimensions ####### #
# ########################################################################### #

@transform(UMAP,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           add_inputs(metadata),
           r"\1/rdims.visualisation.dir/plot.rdims.factor.sentinel")
def plotRdimsFactors(infiles, outfile):
    '''
       Visualise factors of interest on the UMAP.
    '''

    infile, export_sentinel = infiles

    metadata_table = os.path.join(os.path.dirname(export_sentinel),
                                  "metadata.tsv.gz")

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    rdims_table = infile.replace(".sentinel",
                                 "." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    color_factors = []

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    color_factors = [ x for x in color_factors if x != "cluster" ]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisFactorDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)

    tex_file = os.path.join(t.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        tex.write("\input{" + os.path.join(t.outdir) + "/UMAP}")

    IOTools.touch_file(outfile)


@follows(UMAP)
@transform(cluster,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           r"\1/\2/rdims.visualisation.dir/plot.rdims.cluster.sentinel")
def plotRdimsClusters(infile, outfile):
    '''
        Visualise the clusters on the UMAP
    '''

    metadata_table = os.path.join(os.path.dirname(infile),
                                  "cluster_ids.tsv.gz")

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    color_factors = "--colorfactors=cluster_id"

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        rdims_table = os.path.join(t.component_dir,
                                   "umap.dir",
                                   "umap." + mindist + ".tsv.gz")

        umap_spec = "umap.mindist_" + mindist

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --method=%(umap_spec)s
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisClusterDir
                   &> %(mindist_log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

        statements.append(statement)
    P.run(statements, **t.resources)

    tex_file = os.path.join(t.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        for mindist in mindists:
            tex.write("\input{" + t.outdir + "/umap.mindist_" + mindist + "}\n")

    IOTools.touch_file(outfile)


@active_if(PARAMS["run_singleR"])
@transform(UMAP,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           r"\1/singleR.dir/rdims.plots.sentinel")
def plotRdimsSingleR(infile, outfile):
    '''
        Plot the SingleR primary identity assignments on a UMAP
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    rdims_table = os.path.join(t.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")
    
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    if not os.path.exists(api_loc):
        raise ValueError("singleR api not found in source cellhub folder")

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]
    
    references = [x for x in references if x != "summary"]
    
    stats = []
    
    for reference in references:
    
        labels = os.path.join(api_loc, reference, "labels.tsv.gz")
    
        statement  = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                        --table=%(rdims_table)s
                        --metadata=%(labels)s
                        --colorfactors=pruned.labels
                        --analysisname=%(reference)s
                        --pointsize=%(plot_pointsize)s
                        --pointalpha=%(plot_pointalpha)s
                        --pointpch=%(plot_pointpch)s
                        --pdf=%(plot_pdf)s
                        --outdir=%(outdir)s
                        --plotdirvar=rdimsVisSingleRDir
                        &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())
                
        stats.append(statement)

    P.run(stats, **t.resources)
    IOTools.touch_file(outfile)


#endregion

#region singleR

@active_if(PARAMS["run_singleR"])
@transform(metadata,
           regex(".*/metadata.sentinel"),
           "singleR.dir/singleR.plots.sentinel")
def plotSingleR(infile, outfile):
    '''
       Make singleR heatmaps for the references present on the cellhub API.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    metadata = infile.replace(".sentinel", ".tsv.gz")
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    if not os.path.exists(api_loc):
        raise ValueError("singleR api not found in source cellhub folder: " + api_loc)

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]
    
    references = [x for x in references if x != "summary"]
    
    stats = []
    
    for reference in references:
        
        scores = os.path.join(api_loc, reference, "scores.tsv.gz")
        labels = os.path.join(api_loc, reference, "labels.tsv.gz")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_singleR_plots.R
                       --metadata=%(metadata)s
                       --scores=%(scores)s
                       --labels=%(labels)s
                       --reference=%(reference)s
                       --outdir=%(outdir)s
                       --pdf=%(plot_pdf)s
                       &> %(log_file)s
                       ''' % dict(PARAMS, **t.var, **locals())

        stats.append(statement)

    P.run(stats, **t.resources)
    IOTools.touch_file(outfile)

@active_if(PARAMS["run_singleR"])
@follows(plotSingleR, plotRdimsSingleR)
@transform(UMAP,
           regex(r"(.*)/umap.dir/umap.sentinel"),
           r"\1/singleR.dir/summary.sentinel")
def summariseSingleR(infile, outfile):
    '''
       Collect the single R plots into a section for the Summary report.
    '''

    t = C.setup(infile, outfile, PARAMS)
    
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]

    singleR_path = "singleR.dir"

    singleR_umap_path = os.path.join(Path(infile).parents[1],
                                "singleR.dir")

    latex_path = outfile.replace(".sentinel", ".tex")

    with open(latex_path, "w") as tex:

        for reference in references:

            # heatmap
            tex.write(template.subsection % {"title": reference})
            tex.write("\n")

            heatmap_path = os.path.join(singleR_path,
                                        reference + ".heatmap")


            if(os.path.exists(heatmap_path + ".png")):
                heatmap_fig = {"width": "1", "height": "0.9",
                               "path": heatmap_path,
                               "caption": "singleR predictions (" +\
                               reference + ")"}

                tex.write(textwrap.dedent(
                    template.figure % heatmap_fig))
                tex.write("\n")

            umap_path = os.path.join(singleR_umap_path,
                                     "umap." + reference + ".pruned.labels")

            if(os.path.exists(umap_path + ".png")):

                umap_fig = {"width": "1", "height": "0.9",
                            "path": umap_path,
                            "caption": "pruned singleR predictions (" +\
                            reference + ")"}

                tex.write(textwrap.dedent(
                    template.figure % umap_fig))

                tex.write("\n")
                
    IOTools.touch_file(outfile)

#endregion

#region Stats

# ########################################################################### #
# ################# plot per-cluster summary statistics ##################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           add_inputs(metadata),
           r"\1/group.numbers.dir/plot.group.numbers.sentinel")
def plotGroupNumbers(infiles, outfile):
    '''
       Plot statistics on cells by group, e.g. numbers of cells per cluster.

       Plots are defined on a case-by-case basis in the yaml.
    '''

    cluster_outfile, metadata_outfile = infiles

    t = C.setup(cluster_outfile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    metadata_table = metadata_outfile.replace(".sentinel", ".tsv.gz")

    # we need the yaml as a dict, so...
    config_file = "pipeline_cluster.yml"
    if not os.path.exists(config_file):
        config_file = "%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0]
        if not os.path.exists(config_file):
            raise ValueError("Config file not found in plot group numbers")

    with open(config_file) as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params = params["summaries"]

    statements = []
    for summary_key in params.keys():

        summary = params[summary_key].copy()

        options = []

        # populate the Rscript options from the yaml dictionary
        for k, v in summary.items():
            if v == "None" or v == None or v == False or k == "title":
                pass
            elif v == True:
                options.append("--" + k)
            elif k in ["xlab", "ylab"]:
                options.append("--" + k + "=\"" + str(v) + "\"")
            else:
                options.append("--" + k + "=" + str(v))

        options = "\n".join(options)

        t.log_file = os.path.join(t.outdir, summary_key + ".log")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_group_numbers.R
                   --metadata=%(metadata_table)s
                   --clusters=%(cluster_ids)s
                   --title=%(summary_key)s
                   %(options)s
                   --outdir=%(outdir)s
                   --plotdirvar=groupNumbersDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

        statements.append(statement)

    P.run(statements, **t.resources)

    # write out the latex snippet...
    with open(os.path.join(t.outdir, "number.plots.tex"),"w") as tex:

        for fig in params.keys():

            if("_" in params[fig]["title"]):
               raise ValueError("Underscores are not allowed in the plot"
                                " titles (due to issues with latex...")

            # Add the figures, one per subsection, escaping underscores.
            tex.write(template.subsection %
                      {"title": params[fig]["title"]})

            tex.write("\n")

            fig_path = os.path.join(t.outdir, fig)

            if(os.path.exists(fig_path + ".png")):
                fig_spec = {"width": "1", "height": "0.9",
                            "path": fig_path,
                            "caption": params[fig]["title"]
                            }

                tex.write(textwrap.dedent(
                    template.figure % fig_spec))
                tex.write("\n")

    IOTools.touch_file(outfile)

@follows(metadata)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/stats.dir/cluster.stats.sentinel")
def clusterStats(infile, outfile):
    '''
       Compute per-cluster statistics (e.g. mean expression level).
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    if PARAMS["markers_conserved"]:

        subset_factor = PARAMS["markers_conserved_factor"]
        subset_stat="--subset_factor=" + subset_factor

        levels_file = os.path.join("metadata.dir",
                                   subset_factor + ".levels")
        
        subset_levels = [x for x in 
                         pd.read_csv(levels_file, header= None)[0].values]
        
        #subset_levels = [x for x in adata.obs[subset_factor].cat.categories]

    else:
        subset_stat=""
        subset_levels = ["all"]
    
    statements = []
    for subset_level in subset_levels:

        outfile_name = os.path.join(t.outdir, 
                                    ".".join([subset_level, "stats.tsv.gz"]))
        log_file_name = outfile_name.replace(".tsv.gz", ".log")

        stat = '''python %(cellhub_code_dir)s/python/cluster_stats.py
                            --anndata=%(source_anndata)s
                            %(subset_stat)s
                            --subset_level=%(subset_level)s
                            --clusterids=%(cluster_ids)s
                            --outfile=%(outfile_name)s
                            &> %(log_file_name)s
                    ''' % dict(PARAMS, **t.var, **locals())
    
        statements.append(stat)

    P.run(statements, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Cluster Markers

# ########################################################################### #
# ############# Cluster marker identification and visualisation ############# #
# ########################################################################### #

@follows(clusterStats, metadata)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/markers.dir/markers.sentinel")
def findMarkers(infile, outfile):
    '''
        Find per-cluster marker genes. Just execute the rank_genes_groups routine, 
        no filtering here.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    statements = []
    
    for i in t.clusters:
    
        if str(i) == "911":
            continue

        if PARAMS["markers_conserved"]:

            subset_factor = PARAMS["markers_conserved_factor"]
            subset_stat="--subset_factor=" + subset_factor

            levels_file = os.path.join("metadata.dir",
                                   subset_factor + ".levels")

            subset_levels = [x for x in 
                             pd.read_csv(levels_file, header= None)[0].values]
            
        else:
            subset_stat = ""
            subset_levels = ["all"]
            
        
        for subset_level in subset_levels:

            #outdir = os.path.join(t.outdir, subset_level + ".level.dir")

            outfile_name = os.path.join(t.outdir, 
                                        ".".join([str(i), subset_level, "markers.tsv.gz"]))
            
            log_file_name = outfile_name.replace(".tsv.gz", ".log")
            
            stats_file = os.path.join(t.cluster_dir,
                                      "stats.dir",
                                      subset_level + ".stats.tsv.gz")
            
            sizes_file = os.path.join(t.cluster_dir,
                                      "stats.dir",
                                      subset_level + ".sizes.tsv.gz")

            stat = '''python %(cellhub_code_dir)s/python/cluster_markers.py
                            --anndata=%(source_anndata)s
                            %(subset_stat)s
                            --subset_level=%(subset_level)s
                            --clusterids=%(cluster_ids)s
                            --cluster=%(i)s
                            --group_means=%(stats_file)s
                            --group_sizes=%(sizes_file)s
                            --method=%(markers_test)s
                            --pseudocount=%(markers_pseudocount)s
                            --outfile=%(outfile_name)s
                            &> %(log_file_name)s
                    ''' % dict(PARAMS, **t.var, **locals())
            

            statements.append(stat)

    P.run(statements, **t.resources)
    IOTools.touch_file(outfile)


@follows(findMarkers)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           add_inputs(metadata),
           r"\1/\2/markers.dir/markers.summary.sentinel")
def summariseMarkers(infiles, outfile):
    '''
       Summarise the differentially expressed marker genes. P-values
       are adjusted per-cluster are filtering out genes with low expression
       levels and fold changes. Per-cluster gene universes are prepared for
       the pathway analysis.
    '''

    t = C.setup(infiles[0], outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    cluster_sentinel, metadata = infiles
    
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
    
    marker_files = glob.glob(os.path.join(t.outdir, "*.markers.tsv.gz"))
    marker_files = ",".join(marker_files)
    
    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_summarise_markers.R
                   --marker_files=%(marker_files)s
                   --minpct=%(markers_min_pct)s
                   --minfc=%(markers_min_fc)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())
                
    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Plot Cluster Markers

@active_if(PARAMS["run_top_marker_heatmap"])
@transform(summariseMarkers,
           regex(r"(.*)/(.*)/(.*)/markers.summary.sentinel"),
           add_inputs(loom, metadata),
           r"\1/\2/\3/topMarkerHeatmap.sentinel")
def topMarkerHeatmap(infiles, outfile):
    '''
       Make the top marker heatmap.
    '''

    markers, loom, metadata = infiles
    
    t = C.setup(markers, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    marker_table = os.path.join(os.path.dirname(markers),
                                "markers.summary.table.tsv.gz")
    
    
    loom_dir = os.path.dirname(loom) 
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
    
    matrix_loc = "matrix"
    
    if PARAMS["source_heatmap_matrix"] == "X":
        loom_file = os.path.join(loom_dir, "X.loom")
        scale= "FALSE"
        
    elif PARAMS["source_heatmap_matrix"] == "log1p":
        loom_file = os.path.join(loom_dir, "log1p.loom")
        scale = "TRUE"
        
    else:
        raise ValueError('source heatmap matrix parameter must be "X" or "log1p"')

    if PARAMS["plot_subgroup"] is not None:
        subgroup = '''--subgroup=%(plot_subgroup)s''' % PARAMS
    else:
        subgroup = ""

    statement = '''
    Rscript %(cellhub_code_dir)s/R/scripts/cluster_top_marker_heatmap.R
                   --loom=%(loom_file)s
                   --clusterids=%(cluster_ids)s
                   --metadata=%(metadata_file)s
                   --matrix_loc=%(matrix_loc)s
                   --scale=%(scale)s
                   --markers=%(marker_table)s
                   --pdf=%(plot_pdf)s
                   %(subgroup)s
                   --outdir=%(outdir)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_characterise_markers"])
@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/markers.summary.sentinel"),
           r"\1/de.plots.dir/characteriseClusterMarkers.tex")
def dePlots(infile, outfile):
    '''
        Make per-cluster diagnoistic differential expression plots
        (MA and volcano plots).
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")

    statements = []
    tex = []

    for i in t.clusters:

        if str(i) == "911":
            continue

        t.log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/scripts/cluster_de_plots.R
                    --degenes=%(marker_table)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    --pdf=%(plot_pdf)s
                    --plotdirvar=clusterMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

        cluster_tex_file = ".".join(["characterise.degenes", str(i), "tex"])
        tex.append("\\input{\\clusterMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements, **t.resources)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/markers.summary.sentinel"),
           add_inputs(loom, metadata),
           r"\1/marker.plots.dir/marker.plots.sentinel")
def markerPlots(infiles, outfile):
    '''
       Make the per-cluster marker plots
       TODO: add some version of split dot plots back.. 
    '''

    markers, loom, metadata = infiles

    t = C.setup(markers, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    marker_table = os.path.join(os.path.dirname(markers),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    markers = pd.read_csv(marker_table, sep="\t")
    clusters_with_markers = [x for x in markers.cluster.unique()]
    
    loom_dir = os.path.dirname(loom) 
    loom_file = os.path.join(loom_dir, "log1p.loom")
    
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
        
    if PARAMS["source_heatmap_matrix"] == "X":
        scaled_loom_file = os.path.join(loom_dir, "X.loom")
        scaled_loom = "--scaled_loom=" + scaled_loom_file
    elif PARAMS["source_heatmap_matrix"] == "log1p":
        scaled_loom = ""
    else:
        raise ValueError('source heatmap matrix parameter must be "X" or "log1p"')

    statements = []

    rdims_table = os.path.join(t.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    if PARAMS["plot_subgroup"] is not None:
        group_opt = "--group=" + PARAMS["plot_subgroup"]
    else:
        group_opt = ""

    for i in clusters_with_markers:

        if str(i) == "911":
            continue

        t.log_file = outfile[:-len(".sentinel")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/scripts/cluster_marker_plots.R
                    --markers=%(marker_table)s
                    --loom=%(loom_file)s
                    %(scaled_loom)s
                    --metadata=%(metadata_file)s
                    --clusterids=%(cluster_ids)s
                    --rdimstable=%(rdims_table)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    %(group_opt)s
                    --pdf=%(plot_pdf)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

        statements.append(statement)

    P.run(statements, **t.resources)

    IOTools.touch_file(outfile)


@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/(.*).sentinel"),
           r"\1/marker.de.plots.dir/plotMarkerNumbers.sentinel")
def plotMarkerNumbers(infile, outfile):
    '''
       Summarise the numbers of marker genes for each cluster.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")


    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_marker_numbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   --minfc=2
                   --minpadj=0.05
                   --plotdirvar=clusterMarkerDEPlotsDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Markers <Target>

# ########################################################################### #
# ########### marker gene (and within cluster DE) analysis ################## #
# ########################################################################### #

@follows(#characteriseClusterMarkers,
         topMarkerHeatmap,
         plotMarkerNumbers,
         dePlots,
         markerPlots)
@files(None, "markers.sentinel")
def markers(infile, outfile):
    '''
       Target to run marker gene plotting tasks.
    '''

    IOTools.touch_file(outfile)

#endregion

#region Geneset Analysis

# ########################################################################### #
# ######################### Geneset Analysis ################################ #
# ########################################################################### #

def parseGMTs(param_keys=["gmt_pathway_files_"]):
    '''
       Helper function for parsing the lists of GMT files
    '''

    all_files = []
    all_names = []

    for param_key in param_keys:


        gmts = [x for x in PARAMS.keys()
                if x.startswith(param_key)]

        if len(gmts) > 0:
            all_files += [PARAMS[x] for x in gmts]

            all_names += [x.replace(param_key, "")
                              for x in gmts]

    if len(all_files) == 0:
        all_files = "none"
        all_names = "none"
    else:
        all_files = ",".join(all_files)
        all_names = ",".join(all_names)

    return all_names, all_files


# ------------------- < between cluster geneset analysis > ------------------ #

@active_if(PARAMS["run_genesets"])
@follows(summariseMarkers)
@transform(findMarkers,
           regex(r"(.*)/markers.dir/markers.sentinel"),
           r"\1/genesets.dir/geneset.analysis.sentinel")
def genesetAnalysis(infile, outfile):
    '''
    Naive geneset over-enrichment analysis of cluster marker genes.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog = infile

    t = C.setup(findMarkersLog, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    statements = []

    for i in t.clusters:

        if str(i) == "911":
            continue

        cluster_log_file = os.path.join(t.outdir, "geneset.analysis." + str(i) + ".log")

        markers = os.path.join(t.indir, "markers.summary.table.tsv.gz")

        universe = os.path.join(
            t.indir, str(i) + ".universe.tsv.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(cellhub_code_dir)s/R/scripts/cluster_geneset_analysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(source_species)s
                            --annotation=%(cellhub_ensembl_annotations)s
                            --kegg_pathways=%(cellhub_kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(genesets_marker_adjpthreshold)s
                            --direction=positive
                            --outdir=%(outdir)s
                            &> %(cluster_log_file)s
                      ''' % dict(PARAMS, **t.var, **locals()))

    P.run(statements, **t.resources)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_genesets"])
@transform(genesetAnalysis,
           regex(r"(.*)/geneset.analysis.sentinel"),
           r"\1/summarise.geneset.analysis.sentinel")
def summariseGenesetAnalysis(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of cluster marker genes.

    Enriched pathways are saved as dotplots and exported in excel format.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_low"])

    # need to sort out the dependencies properly!
    genesetdir = os.path.dirname(infile)

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    # Read clusters
    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    show_detailed = str(PARAMS["genesets_show_detailed"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_geneset_summary.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --clusters=%(cluster_table)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/cluster.genesets
                         --prefix=genesets
                         --plotdirvar=clusterGenesetsDir
                         --pdf=%(plot_pdf)s
                    &> %(log_file)s
                      ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)

#endregion

#region Genesets <Target>

# ---------------------- < geneset analysis target > ---------------------- #

@files([summariseGenesetAnalysis],
       "genesets.sentinel")
def genesets(infile, outfile):
    '''
       Intermediate target to run geneset tasks
    '''

    IOTools.touch_file(outfile)

#endregion

#region Plots <Target>

# ########################################################################### #
# ##################### Target to collect plots ############################# #
# ########################################################################### #

@files([
         summariseSingleR,
         compareClusters,
         clustree,
         paga,
         plotRdimsFactors,
         plotRdimsClusters,
         plotRdimsSingleR,
         plotGroupNumbers,
         dePlots,
         markerPlots], "plots.sentinel")
def plots(infile, outfile):
    '''
       Target to run all the plotting functions.
    '''

    IOTools.touch_file(outfile)

#endregion

#region Report Variables

# ########################################################################### #
# ################## PDF report generation (via Latex) ###################### #
# ########################################################################### #

# High quality pdf reports are generated which can be easily shared.
#
# The reports incorporate raster (png) graphics. PDF versions of each graphic
# can also be generation (see yaml.)

# -------------------------- < Define variables > --------------------------- #

@transform(plotRdimsClusters,
           regex("(.*)/rdims.visualisation.dir/plot.rdims.cluster.sentinel"),
           add_inputs(taskSummary, markers, genesets, plots, 
                      summariseGenesetAnalysis,summariseSingleR),
           r"\1/latex.dir/report.vars.sentinel")
def latexVars(infiles, outfile):
    '''
       Prepare a file containing the latex variable definitions for the reports.
    '''
    infile = infiles[0]
     
    t = C.setup(infile, outfile, PARAMS)

    outfile_name = outfile.replace(".sentinel",".sty")
    
    statement = '''python %(cellhub_code_dir)s/python/cluster_report_vars.py
                            --infile=%(infile)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)
    
#endregion

#region Summary Report

# ----------------------------- < Summary report > --------------------------- #

@transform(latexVars,
           regex("(.*)/report.vars.sentinel"),
           r"\1/summary.report.sentinel")
def summaryReportSource(infile, outfile):
    '''
       Write the latex source for the summary report.
    '''
    t = C.setup(infile, outfile, PARAMS)

    latex_vars = infile.replace(".sentinel", ".sty")
    outfile_name = outfile.replace(".sentinel", ".tex")
    
    statement = '''python %(cellhub_code_dir)s/python/cluster_summary_report.py
                            --latexvars=%(latex_vars)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


@transform(summaryReportSource,
           regex("(.*)/summary.report.sentinel"),
           r"\1/summaryReport.sentinel")
def summaryReport(infile, outfile):
    '''
       Compile the summary report to PDF format.
    '''
     
    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    compilation_dir = os.path.join(t.outdir, 
                                   "summary.report.dir")
    
    out_pdf = os.path.basename(infile).replace(".sentinel",".pdf")
    
    try:
        shutil.rmtree(compilation_dir)
    except FileNotFoundError:
        pass

    os.mkdir(compilation_dir)

    source_tex = infile.replace(".sentinel", ".tex")
    log_file = outfile.replace(".sentinel", ".log")

    statement = ''' pdflatex -output-directory=%(compilation_dir)s
                             %(draft_mode)s
                             %(source_tex)s
                    &> %(log_file)s
                ''' 
                
    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement, **t.resources)

    draft_mode = ""
    P.run(statement, **t.resources)
   
    outfile_name = outfile.replace(".sentinel", ".pdf")
   
   # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, out_pdf),
            outfile_name)

    IOTools.touch_file(outfile)

#endregion

#region Marker Report

# ------------------------------ < Marker report > --------------------------- #


@follows(markerPlots, summariseMarkers)
@transform(latexVars,
           regex("(.*)/report.vars.sentinel"),
           r"\1/marker.report.sentinel")
def markerReportSource(infile, outfile):
    '''
       Write the latex source file  for the marker report.
    '''
    
    t = C.setup(infile, outfile, PARAMS)

    marker_table = os.path.join(t.cluster_dir,
                            "markers.dir",
                            "markers.summary.table.tsv.gz")

    latex_vars = infile.replace(".sentinel", ".sty")
    outfile_name = outfile.replace(".sentinel", ".tex")
    
    statement = '''python %(cellhub_code_dir)s/python/cluster_marker_report.py
                            --latexvars=%(latex_vars)s
                            --markers=%(marker_table)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


@transform(markerReportSource,
           regex("(.*)/marker.report.sentinel"),
           r"\1/clusterMarkerReport.sentinel")
def markerReport(infile, outfile):
    '''
       Prepare a PDF report visualising the discovered cluster markers.
    '''

    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])
    
    compilation_dir = os.path.join(t.outdir, 
                                   "marker.report.dir")
    
    out_pdf = os.path.basename(infile).replace(".sentinel",".pdf")
    
    try:
        shutil.rmtree(compilation_dir)
    except FileNotFoundError:
        pass

    os.mkdir(compilation_dir)

    source_tex = infile.replace(".sentinel", ".tex")
    log_file = outfile.replace(".sentinel", ".log")

    statement = ''' pdflatex -output-directory=%(compilation_dir)s
                             %(draft_mode)s
                             %(source_tex)s
                    &> %(log_file)s
                '''
    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement, **t.resources)

    draft_mode = ""
    P.run(statement, **t.resources)
    
    outfile_name = outfile.replace(".sentinel", ".pdf")
   
    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, out_pdf),
            outfile_name)
    
    IOTools.touch_file(outfile)


# endregion

#region Export Reports

@follows(mkdir("reports.dir"), markerReport)
@transform(summaryReport,
           regex(r"out.(.*).comp.dir/cluster.(.*).dir/latex.dir/summaryReport.sentinel"),
           r"reports.dir/\1.comps.\2.res/export.sentinel")
def export(infile, outfile):
    '''
       Link output files to a directory in the "reports.dir" folder.

       Prepare folders containing the reports, differentially expressed genes
       and geneset tables for each analysis.
       
       TODO: link in the cellxgene anndata files.
    '''

    t = C.setup(infile, infile, PARAMS)

    out_dir = Path(outfile).parents[0]

    run_dir = Path(infile).parents[1]

    try:
        shutil.rmtree(out_dir)
    except FileNotFoundError:
        pass

    os.mkdir(out_dir)

    between_xlsx = "markers.between." + \
                   str(PARAMS["findmarkers_between_testfactor"]) + \
                   ".summary.table.xlsx"

    targets = [os.path.join(run_dir,"latex.dir","summaryReport.pdf"),
               os.path.join(run_dir,"latex.dir","clusterMarkerReport.pdf"),
               os.path.join(run_dir,"markers.dir","markers.summary.table.xlsx"),
               os.path.join(run_dir,"condition.markers.dir",between_xlsx),
               os.path.join(run_dir, "genesets.dir","cluster.genesets.xlsx"),
               os.path.join(run_dir, "condition.genesets.dir","condition.genesets.xlsx")]

    for target_file in targets:

        if os.path.exists(target_file):
        
            target = os.path.basename(target_file)
            link_name = os.path.join(out_dir, target)

            os.symlink(os.path.relpath(target_file, start=out_dir),
                       link_name)

    IOTools.touch_file(outfile)


# --------------------------- < report target > ----------------------------- #

@follows(export)
def report():
    '''
       Target for building the reports.
    '''
    pass

#endregion

#region Additional Outputs

# ########################################################################### #
# ##################### Generate cellxgene output ########################### #
# ########################################################################### #

@follows(markers)
@transform(UMAP,
           regex(r"(.*)/umap.dir/umap.sentinel"),
           r"\1/cellxgene.sentinel")
def cellxgene(infile, outfile):
    '''
       Export an anndata object for cellxgene.
    '''
        
    t = C.setup(infile, outfile, PARAMS,
                memory=PARAMS["resources_memory_standard"])

    umap_path = os.path.join(os.path.dirname(infile),
                             ".".join(["umap", 
                                       str(PARAMS["umap_mindist"]), 
                                       "tsv.gz"]))

    cluster_paths = []
    cluster_names = []
    cxg_res = PARAMS["cellxgene_resolution"]
    if cxg_res == "all":

        for res in t.resolutions:
            cluster_dir = os.path.join(t.component_dir,
                            ".".join(["cluster", str(res), "dir"]))
            cluster_paths.append(os.path.join(cluster_dir, "cluster_ids.tsv.gz"))
            cluster_names.append("cluster_" + str(res))
    else:
       
        cluster_dir = os.path.join(t.component_dir,
                            ".".join(["cluster", str(cxg_res), "dir"]))
        if not os.path.exists(cluster_dir):
            raise ValueError("Path to selected clustering resolution does not exist")
            
        cluster_paths.append(os.path.join(cluster_dir,"cluster_ids.tsv.gz"))
        cluster_names.append("cluster" + str(cxg_res))
        
    cluster_paths=",".join(cluster_paths)
    cluster_names=",".join(cluster_names)
    
    # out_file = outfile.replace(".sentinel", ".h5ad")

    statement='''python %(cellhub_code_dir)s/python/cluster_cellxgene.py
                 --source_anndata=%(source_anndata)s
                 --obs=%(cellxgene_obs)s
                 --umap=%(umap_path)s
                 --umap_facet_x=%(cellxgene_facet_umap_x)s
                 --umap_facet_y=%(cellxgene_facet_umap_y)s
                 --cluster_paths=%(cluster_paths)s
                 --cluster_names=%(cluster_names)s
                 --cluster_split=%(cellxgene_cluster_split)s
                 --adt=None
                 --outfile=%(out_file)s.h5ad
    ''' % dict(PARAMS, **t.var, **locals())

    P.run(statement, **t.resources)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ######################### Auxillary functions ############################# #
# ########################################################################### #

# TODO
# @transform(scanpyCluster,
#            regex(r"(.*)/cluster.sentinel"),
#            r"\1/cluster_counts.rds")
# def pseudobulks(infile, outfile):
#     '''
#     Aggregate UMI counts across cells within cluster to form pseudobulks.
#     '''


#endregion

#region Full <Target> and Main

# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #

@follows(report, cellxgene)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #

def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))

#endregion
