"""===========================
Pipeline fetch cells
===========================

Overview
========

This pipeline fetches a given set of cells from market matrices or
loom files into a single market matrix file.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to fetch the cells into a new directory. Fetching
of multiple datasets per-directory is (deliberately) not supported.

The pipeline requires a configured :file:`pipeline_fetch_cells.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_fetch_cells.py config


Inputs
------

The pipeline will fetch cells from a cellhub instance according to
the parameters specified in the local pipeline_fetch_cell.yml file.


The location of the cellhub instances must be specificed in the yml: ::

   cellhub:
       location: /path/to/cellhub/instance

The specifications of the cells to retrieve must be provided as an SQL
statement (query) that will be executed against the "final" table of the cellhub
database: ::

    cellhub:
        sql_query: >-
            select * from final
            where pct_mitochondrial < 10
            and ngenes > 200;



The cells will then be automatically retrieved from the API.

Cell barcodes are set according to the "barcode_id" column which is
set by pipeline_cellranger_multi.py and have the format "UMI-1-LIBRARY_ID"

Dependencies
------------

This pipeline requires:


Pipeline output
===============

The pipeline outputs a folder containing a single market matrix
that contains the requested cells.

"""

import os
import sys
import gzip
from shutil import copyfile

from pathlib import Path
import pandas as pd
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks.control as C
import cellhub.tasks.fetch_cells as fetch_cells

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline_fetch_cells.yml" % os.path.splitext(__file__)[0],
     "../pipeline_fetch_cells.yml",
     "pipeline_fetch_cells.yml"])

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))

# ------------------------------ < functions > ------------------------------ #


# ########################################################################### #
# ############################# pipeline tasks ############################## #
# ########################################################################### #

@follows(mkdir("fetch.cells.dir"))
@files(os.path.join(PARAMS["cellhub_location"],"celldb.dir/csvdb"),
       "fetch.cells.dir/cell.table.sentinel")
def fetchCells(infile, outfile):
    '''Fetch the table of the user's desired cells from the database
       effectively, cell-metadata tsv table.
    '''

    cell_table = outfile.replace(".sentinel", ".tsv.gz")

    if(PARAMS["sample"]=="all"):
        sample = ""
    else:
        take = int(PARAMS["sample"]) + 1
        sample = '''| body shuf | awk 'NR <= %(take)s' ''' % locals()

    statement ='''body() {
                   IFS= read -r header;
                   printf '%%s\\n' "$header";
                  "$@";
                  };

              sqlite3 -header %(infile)s
                      -separator $'\\t'
                      '%(cellhub_sql_query)s'
                  %(sample)s
                  | gzip -c
                  > %(cell_table)s'''

    P.run(statement)
    IOTools.touch_file(outfile)


@follows(mkdir("fetch.cells.dir/barcode.subsets.dir"))
@subdivide(fetchCells,
           formatter(),
           "fetch.cells.dir/barcode.subsets.dir/*.tsv.gz",
           "fetch.cells.dir/barcode.subsets.dir/subdivide.sentinel")
def barcodeSubsets(infile, output_files, sentinel):
    '''
    Generate the sets of barcodes to retrieve from each of the
    source matrices. (These will be used for extraction of data from
    all of the specified modalities).
    '''

    cell_tab = infile.replace(".sentinel",".tsv.gz")

    cells = pd.read_csv(cell_tab, sep="\t")

    # note the matrix_name column is usually the "library_id"
    matrix_ids = [x for x in cells[PARAMS['matrix_name']].unique()]

    for matrix_id in matrix_ids:

        out_file = os.path.join(os.path.dirname(sentinel),
                                matrix_id + ".tsv.gz")

        cell_subset = cells["barcode_id"][cells[
                PARAMS["matrix_name"]] == matrix_id]

        cell_subset.to_csv(out_file,
                           header=False,
                           index=False,
                           compression="gzip")

    IOTools.touch_file(sentinel)


# ########################################################################### #
# ######################### fetch GEX data ################################## #
# ########################################################################### #

@follows(mkdir("fetch.cells.dir/GEX.mtx.subsets.dir"))
@transform(barcodeSubsets,
           regex(r"fetch.cells.dir/barcode.subsets.dir/(.*).tsv.gz"),
           r"fetch.cells.dir/GEX.mtx.subsets.dir/\1/matrix.mtx.gz")
def GEXSubsets(infile, outfile):
    '''
    Extract the GEX cell subsets from the parent mtx.
    '''

    matrix_subset_dir = os.path.dirname(infile)
    matrix_id = os.path.basename(infile).replace(".tsv.gz","")

    outdir = os.path.dirname(outfile)

    fetch_cells.get_cell_subset(barcodes=infile,
                                modality="GEX",
                                matrix_id=matrix_id,
                                outdir=outdir,
                                PARAMS=PARAMS,
                                data_subset="filtered")


@follows(mkdir("fetch.cells.dir/GEX.mtx.full.dir"))
@merge(GEXSubsets,
       "fetch.cells.dir/GEX.mtx.full.dir/matrix.sentinel")
def mergeGEXSubsets(infiles, outfile):
    '''
    Merge the GEX cell subsets into a single mtx.
    '''

    out_mtx_file = outfile.replace(".sentinel",".mtx.gz")

    fetch_cells.merge_subsets(infiles, out_mtx_file, PARAMS)

    IOTools.touch_file(outfile)


@active_if(PARAMS["GEX_downsample"])
@follows(mkdir("fetch.cells.dir/GEX.mtx.subsampled.dir"))
@transform(mergeGEXSubsets,
           regex(r"fetch.cells.dir/GEX.mtx.full.dir/matrix.sentinel"),
           add_inputs(fetchCells),
           r"fetch.cells.dir/GEX.mtx.subsampled.dir/downsample.sentinel")
def downsampleGEX(infiles, outfile):
    '''
    Down-sample transcripts given a cell-metadata variable

    TODO: incorporate down-sampling into the fetching
          of the cell subsets.
    '''

    merge_sentinel, fetchCells_sentinel = infiles
    outdir = os.path.dirname(outfile)
    agg_matrix_dir = os.path.dirname(merge_sentinel)
    cell_metadata = fetchCells_sentinel.replace(".sentinel", ".tsv.gz")

    fetch_cells.downsample_gex(agg_matrix_dir,
                               cell_metadata,
                               outdir,
                               PARAMS)

    IOTools.touch_file(outfile)


@transform([mergeGEXSubsets, downsampleGEX],
           regex(r"fetch.cells.dir/GEX.mtx.(.*).dir/.*.sentinel"),
           add_inputs(fetchCells),
           r"fetch.cells.dir/GEX.anndata.\1.dir/matrix.sentinel")
def exportAnnData(infiles, outfile):
    '''
       Export h5ad anndata matrices for downstream analysis with
       scanpy
    '''

    mtx, obs = infiles
    mtx_dir = os.path.dirname(mtx)
    obs_file = obs.replace(".sentinel",".tsv.gz")
    outdir = os.path.dirname(outfile)
    matrix_name = os.path.basename(outfile).replace(".sentinel",".h5ad")

    fetch_cells.export_anndata(mtx_dir, obs_file, outdir, matrix_name,
                               PARAMS)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ######################### fetch ADT data ################################## #
# ########################################################################### #

# Fetch ADT counts datamatrices from the api here.
@active_if(PARAMS["ADT_fetch"])
@follows(mkdir("fetch.cells.dir/ADT.mtx.subsets.dir"))
@transform(barcodeSubsets,
           regex(r"fetch.cells.dir/barcode.subsets.dir/(.*).tsv.gz"),
           r"fetch.cells.dir/ADT.mtx.subsets.dir/\1/matrix.mtx.gz")
def ADTSubsets(infile, outfile):
    '''
    Extract the ADT cell subsets from the parent mtx.
    '''

    matrix_subset_dir = os.path.dirname(infile)
    matrix_id = os.path.basename(infile).replace(".tsv.gz","")

    outdir = os.path.dirname(outfile)

    fetch_cells.get_cell_subset(barcodes=infile,
                                modality="ADT",
                                matrix_id=matrix_id,
                                outdir=outdir,
                                PARAMS=PARAMS,
                                data_subset="filtered")


@follows(mkdir("fetch.cells.dir/ADT.mtx.full.dir"))
@merge(ADTSubsets,
       "fetch.cells.dir/ADT.mtx.full.dir/matrix.sentinel")
def mergeADTSubsets(infiles, outfile):
    '''
    Merge the ADT cell subsets into a single mtx.
    '''

    out_mtx_file = outfile.replace(".sentinel",".mtx.gz")

    fetch_cells.merge_subsets(infiles, out_mtx_file, PARAMS)

    IOTools.touch_file(outfile)


@transform(mergeADTSubsets,
           regex(r"fetch.cells.dir/ADT.mtx.(.*).dir/.*.sentinel"),
           add_inputs(fetchCells),
           r"fetch.cells.dir/ADT.anndata.\1.dir/matrix.sentinel")
def exportAnnDataADT(infiles, outfile):
    '''
       Export h5ad anndata matrices for downstream analysis with
       scanpy
    '''

    mtx, obs = infiles
    mtx_dir = os.path.dirname(mtx)
    obs_file = obs.replace(".sentinel",".tsv.gz")
    outdir = os.path.dirname(outfile)
    matrix_name = os.path.basename(outfile).replace(".sentinel",".h5ad")

    fetch_cells.export_anndata(mtx_dir, obs_file, outdir, matrix_name,
                               PARAMS)

    IOTools.touch_file(outfile)

# Fetch DSB normalised ADT data from the api here.
@active_if(PARAMS["ADT_fetch"])
@follows(mkdir("fetch.cells.dir/ADT.mtx.dsb.subsets.dir"))
@transform(barcodeSubsets,
           regex(r"fetch.cells.dir/barcode.subsets.dir/(.*).tsv.gz"),
           r"fetch.cells.dir/ADT.mtx.dsb.subsets.dir/\1/matrix.mtx.gz")
def dsbADTSubsets(infile, outfile):
    '''
    Extract the dsb normalized ADT cell subsets from the parent mtx
    '''

    matrix_subset_dir = os.path.dirname(infile)
    matrix_id = os.path.basename(infile).replace(".tsv.gz","")

    outdir = os.path.dirname(outfile)

    fetch_cells.get_cell_subset(barcodes=infile,
                                modality="ADT",
                                matrix_id=matrix_id,
                                outdir=outdir,
                                PARAMS=PARAMS)


@follows(mkdir("fetch.cells.dir/ADT.mtx.dsb.full.dir"))
@merge(dsbADTSubsets,
       "fetch.cells.dir/ADT.mtx.dsb.full.dir/matrix.sentinel")
def mergedsbADTSubsets(infiles, outfile):
    '''
    Merge the dsb normalized ADT cell subsets into a single mtx.
    '''

    out_mtx_file = outfile.replace(".sentinel",".mtx.gz")

    fetch_cells.merge_subsets(infiles, out_mtx_file, PARAMS)

    IOTools.touch_file(outfile)


@transform(mergedsbADTSubsets,
           regex(r"fetch.cells.dir/ADT.mtx.dsb.(.*).dir/.*.sentinel"),
           add_inputs(fetchCells),
           r"fetch.cells.dir/dsbADT.anndata.\1.dir/matrix.sentinel")
def exportAnnDatadsbADT(infiles, outfile):
    '''
       Export h5ad anndata matrices for downstream analysis with
       scanpy
    '''

    mtx, obs = infiles
    mtx_dir = os.path.dirname(mtx)
    obs_file = obs.replace(".sentinel",".tsv.gz")
    outdir = os.path.dirname(outfile)
    matrix_name = os.path.basename(outfile).replace(".sentinel",".h5ad")

    fetch_cells.export_anndata(mtx_dir, obs_file, outdir, matrix_name,
                               PARAMS)

    IOTools.touch_file(outfile)

# ########################################################################### #
# ######################### fetch VDJ_B data ################################ #
# ########################################################################### #

# Fetch BCR data from the api here.


# ########################################################################### #
# ######################### fetch VDJ_T data ################################ #
# ########################################################################### #

# Fetch TCR data from the api here.


# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #


@follows(exportAnnDatadsbADT, exportAnnDataADT, exportAnnData)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
