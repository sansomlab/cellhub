"""
====================
Pipeline fetch cells
====================

Overview
========

This pipeline fetches a given set of cells from market matrices or
loom files into a single market matrix file.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to fetch the cells into a new directory. Fetching
of multiple datasets per-directory is (deliberately) not supported.

The pipeline requires a configured :file:`pipeline_fetch_cells.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_fetch_cells.py config


Inputs
------

The pipeline will fetch cells from a cellhub instance according to
the parameters specified in the local pipeline_fetch_cell.yml file.


The location of the cellhub instances must be specificed in the yml: ::

   cellhub:
       location: /path/to/cellhub/instance

The specifications of the cells to retrieve must be provided as an SQL
statement (query) that will be executed against the "final" table of the cellhub
database: ::

    cellhub:
        sql_query: >-
            select * from final
            where pct_mitochondrial < 10
            and ngenes > 200;



The cells will then be automatically retrieved from the API.

Cell barcodes are set according to the "barcode_id" column which is
set by pipeline_cellranger_multi.py and have the format "UMI-1-LIBRARY_ID"

Dependencies
------------

This pipeline requires:


Pipeline output
===============

The pipeline outputs a folder containing a single market matrix
that contains the requested cells.

"""

import os
import sys
import gzip
from shutil import copyfile

from pathlib import Path
import pandas as pd
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks.control as C
import cellhub.tasks.fetch_cells as fetch_cells

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline_fetch_cells.yml" % os.path.splitext(__file__)[0],
     "../pipeline_fetch_cells.yml",
     "pipeline_fetch_cells.yml"])

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))

# ------------------------------ < functions > ------------------------------ #


# ########################################################################### #
# ############################# pipeline tasks ############################## #
# ########################################################################### #

@follows(mkdir("fetch.cells.dir"))
@files(os.path.join(PARAMS["cellhub_location"],"celldb.dir/csvdb"),
       "fetch.cells.dir/cell.table.sentinel")
def fetchCells(infile, outfile):
    '''Fetch the table of the user's desired cells from the database
       effectively, cell-metadata tsv table.
    '''

    cell_table = outfile.replace(".sentinel", ".tsv.gz")

    if(PARAMS["sample"]=="all"):
        sample = ""
    else:
        take = int(PARAMS["sample"]) + 1
        sample = '''| body shuf | awk 'NR <= %(take)s' ''' % locals()

    statement ='''body() {
                   IFS= read -r header;
                   printf '%%s\\n' "$header";
                  "$@";
                  };

              sqlite3 -header %(infile)s
                      -separator $'\\t'
                      '%(cellhub_sql_query)s'
                  %(sample)s
                  | gzip -c
                  > %(cell_table)s'''

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ######################### fetch GEX data ################################## #
# ########################################################################### #



@follows(mkdir("anndata.dir"))
@files(fetchCells,
       "anndata.dir/anndata.sentinel")
def anndata(infile, outfile):
    '''
    Extract the target cells into a single anndata.
    Note that this currently contains all the modalities

    TODO: support down-sampling
    '''

    cell_table = infile.replace(".sentinel", ".tsv.gz")
    api_path = os.path.join(PARAMS["cellhub_location"],"api")
    outdir = os.path.dirname(outfile)   
    log_file = outfile.replace(".sentinel", ".log")

    statement = '''python %(cellhub_code_dir)s/python/extract_cells_from_h5.py 
                   --cells=%(cell_table)s
                   --api=%(api_path)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)

# @active_if(PARAMS["GEX_downsample"])
# @follows(mkdir("fetch.cells.dir/GEX.mtx.subsampled.dir"))
# @transform(mergeGEXSubsets,
#            regex(r"fetch.cells.dir/GEX.mtx.full.dir/matrix.sentinel"),
#            add_inputs(fetchCells),
#            r"fetch.cells.dir/GEX.mtx.subsampled.dir/downsample.sentinel")
# def downsampleGEX(infiles, outfile):
#     '''
#     Down-sample transcripts given a cell-metadata variable

#     TODO: incorporate down-sampling into the fetching
#           of the cell subsets.
#     '''

#     merge_sentinel, fetchCells_sentinel = infiles
#     outdir = os.path.dirname(outfile)
#     agg_matrix_dir = os.path.dirname(merge_sentinel)
#     cell_metadata = fetchCells_sentinel.replace(".sentinel", ".tsv.gz")

#     fetch_cells.downsample_gex(agg_matrix_dir,
#                                cell_metadata,
#                                outdir,
#                                PARAMS)

#     IOTools.touch_file(outfile)


# @transform([mergeGEXSubsets, downsampleGEX],
#            regex(r"fetch.cells.dir/GEX.mtx.(.*).dir/.*.sentinel"),
#            add_inputs(fetchCells),
#            r"fetch.cells.dir/GEX.anndata.\1.dir/matrix.sentinel")
# def exportAnnData(infiles, outfile):
#     '''
#        Export h5ad anndata matrices for downstream analysis with
#        scanpy
#     '''

#     mtx, obs = infiles
#     mtx_dir = os.path.dirname(mtx)
#     obs_file = obs.replace(".sentinel",".tsv.gz")
#     outdir = os.path.dirname(outfile)
#     matrix_name = os.path.basename(outfile).replace(".sentinel",".h5ad")

#     fetch_cells.export_anndata(mtx_dir, obs_file, outdir, matrix_name,
#                                PARAMS)

#     IOTools.touch_file(outfile)


# # ########################################################################### #
# # ######################### fetch ADT data ################################## #
# # ########################################################################### #

# @active_if(PARAMS["ADT_fetch"])
# @follows(mkdir("fetch.cells.dir/ADT.mtx.subsets.dir"))
# @transform(barcodeSubsets,
#            regex(r"fetch.cells.dir/barcode.subsets.dir/(.*).tsv.gz"),
#            r"fetch.cells.dir/ADT.mtx.subsets.dir/\1/matrix.mtx.gz")
# def ADTSubsets(infile, outfile):
#     '''
#     Extract the ADT cell subsets from the parent mtx.
#     '''

#     matrix_subset_dir = os.path.dirname(infile)
#     matrix_id = os.path.basename(infile).replace(".tsv.gz","")

#     outdir = os.path.dirname(outfile)

#     fetch_cells.get_cell_subset(barcodes=infile,
#                                 modality="ADT",
#                                 matrix_id=matrix_id,
#                                 outdir=outdir,
#                                 PARAMS=PARAMS,
#                                 data_subset="filtered")

# @active_if(PARAMS["ADT_fetch"])
# @follows(mkdir("fetch.cells.dir/ADT.mtx.full.dir"))
# @merge(ADTSubsets,
#        "fetch.cells.dir/ADT.mtx.full.dir/matrix.sentinel")
# def mergeADTSubsets(infiles, outfile):
#     '''
#     Merge the ADT cell subsets into a single mtx.
#     '''

#     out_mtx_file = outfile.replace(".sentinel",".mtx.gz")

#     fetch_cells.merge_subsets(infiles, out_mtx_file, PARAMS)

#     IOTools.touch_file(outfile)

# @active_if(PARAMS["ADT_fetch"])
# @transform(mergeADTSubsets,
#            regex(r"fetch.cells.dir/ADT.mtx.(.*).dir/.*.sentinel"),
#            add_inputs(fetchCells),
#            r"fetch.cells.dir/ADT.anndata.\1.dir/matrix.sentinel")
# def exportAnnDataADT(infiles, outfile):
#     '''
#        Export h5ad anndata matrices for downstream analysis with
#        scanpy
#     '''

#     mtx, obs = infiles
#     mtx_dir = os.path.dirname(mtx)
#     obs_file = obs.replace(".sentinel",".tsv.gz")
#     outdir = os.path.dirname(outfile)
#     matrix_name = os.path.basename(outfile).replace(".sentinel",".h5ad")

#     fetch_cells.export_anndata(mtx_dir, obs_file, outdir, matrix_name,
#                                PARAMS)

#     IOTools.touch_file(outfile)

# ########################################################################### #
# ######################### fetch VDJ_B data ################################ #
# ########################################################################### #

# Fetch BCR data from the api here.


# ########################################################################### #
# ######################### fetch VDJ_T data ################################ #
# ########################################################################### #

# Fetch TCR data from the api here.


# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #


@follows(anndata)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
